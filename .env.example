# Copy to .env (do NOT commit .env)
# sh usage:
#   export GROQ_API_KEY="..."
#   python3 dev-server.py
# or (if you have Node):
#   node dev-server.js

GROQ_API_KEY=
GEMINI_API_KEY=
PORT=3000

# AI routing (dev-server.js)
# - groq: uses GROQ_API_KEY
# - gemini: uses GEMINI_API_KEY
# - ollama: uses local Ollama (no API key)
AI_PROVIDER=groq

# Optional fallback if Groq errors/rate-limits (e.g. "ollama")
AI_FALLBACK_PROVIDER=

# Throttling / retries
AI_MIN_INTERVAL_MS=900
AI_MAX_429_RETRIES=2

# Ollama settings
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:14b
